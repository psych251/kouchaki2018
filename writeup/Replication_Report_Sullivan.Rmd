---
title: Replication of The Link Between Self-Dehumanization and Immoral Behavior by
  Kouchaki, Dobson, Waytz, & Kteily (2018, Psychological Science)
author: "Nicky Sullivan (nsull13@stanford.edu)"
date: "12/10/2019"
output: html_document

---


## Introduction

### Justification for Choice of Experiment

My research interests broadly cover how children learn about and conceptualize social categories, but due to the time limitations working with adults seems significantly more manageable. This study looks at dehumanization in adults, which is closely tied to adults' broader conceptions of social categories. 

### Paper Description

This paper is composed of 3 studies (2 of which are broken down into sub-studies) that broadly look at the links between self-dehumanization and immoral behavior. I will be replicating Study 1a, which tests whether thinking about past unethical behavior will lead to self-dehumanization.

Participants are recruited from Mechanical Turk. They start by recalling an event from the past (either ethical, unethical, or neutral depending on condition) and writing about it. They then complete a 10-item self-dehumanization scale based on the Mind Attribution Scale. There are also two attention checks: one that asks participants to report what topic they were supposed to write about and one as part of the self-dehumanization scale that simply asks them to select "3". Participants will also complete a brief demographic questionnaire.

### Stimuli Required

-Writing prompt  
-Self-dehumanization scale (10 items)  
-Attention check questions (2 items)  
-Demographic questionnaire  

### Challenges

The main challenge will be getting a sample size that is large enough given limited constraints, especially after removing any participants that will be excluded based on the attention checks. 

### Links

Project repository: https://github.com/psych251/kouchaki2018.git  

Original paper: https://github.com/psych251/kouchaki2018/blob/master/original_paper.pdf 

Qualtrics survey: https://stanforduniversity.qualtrics.com/jfe/form/SV_3HOv1q71DqayTXv

Preregistration: https://osf.io/ebwpv/

## Methods

### Power Analysis

The effect size reported in the original paper was a partial eta squared of .04, which can be converted to an f of 0.1938. Using this to conduct a power analysis using G*Power yields the following recommended sample sizes: 80% power: 261; 90% power: 342; 95% power: 417.

Given the financial limits of the class, 80% power is the most reasonable sample size. Unfortunately, even this is likely too large a sample (especially given that the actual sample size will need to be larger considering exclusions).


### Planned Sample

Based on the results of the power analysis, it was determined that we would attempt to match the sample size in the original paper. They originally aimed for 50 participants per condition, and oversampled because of anticipated exclusions. This left them with an initial sample size of 177, and a final sample size of 156. In order to also achieve 50 participants per condition, we will aim to get an initial sample size of 174, which after exclusions will likely leave us with approximately 50 participants per condition. 


### Materials

Quoted directly from original article:

"Participants were asked to recall an event and write about it for a few minutes, providing as many details as possible so that a person reading their entry would understand the situation and how they felt. We used the same instructions used in previous research (Barkan, Ayal, Gino, & Ariely, 2012). In the unethical condition, participants were asked to describe a situation where they did something unethical. In the ethical condition, they were instructed to write about something ethical from their past. In the neutral condition, they wrote about how they spend their evenings and described a typical instance.

"We then measured self-dehumanization with 10 items (e.g., "How capable are you of experiencing emotion?" Î± = .91) from the Mind Attribution Scale, adapted from Kozak, Marsh, and Wegner (2006; 1 = not at all capable, 7 = extremely capable). This measure of reduced mind attribution has been validated as a measure of dehumanization in previous work (K. Gray, Knobe, Sheskin, Bloom, & Barrett, 2011; Khamitov, Rotman, & Piazza, 2016; Waytz & Epley, 2012).

"As an attention check, we asked participants to indicate the topic of their writing task. In addition, we embedded an item on the self-dehumanization scale instructing them to select "3" for that item. They also completed a brief demographic questionnaire."

The exact materials described above will be used in this replication.

### Procedure	

Procedures will follow the description laid out in the Materials section above.

First, quoted directly from the original article, "Participants were informed that they would complete several unrelated surveys." They will then complete the writing prompt described above, with an equal number of participants being placed into each of the three conditions (ethical, unethical, neutral). Participants will then complete an attention check (described above) asking them to select the topic of their writing task. All participants will then complete the self-dehumanization scale described above, which will include an attention check item as described above. Finally, all participants will complete a brief demographic questionnaire (described above).

### Analysis Plan

First, participants will be excluded if they "failed to follow instructions to write an essay or failed the attention check". This leaves three possible reasons that participants could be excluded:
1) Not completing the writing portion of the survey
2) Incorrectly answering the question that asks what the topic of their writing prompt was
3) Failing to select '3' on the attention check question embedded in the self-dehumanization measurement

Then, individual participants' responses on the self-dehumanization scale will be averaged into a self-dehumanization score. None of the items are reverse-coded, so this will involve simply taking the mean response across the 10 questions comprising the scale (the item instructing participants to select "3" as an attention check will be excluded from this calculation).

The **key analysis of interest** will involve conducting a one-way analysis of variance test comparing self-dehumanization mean scores (described above) across the three conditions (ethical writing prompt, unethical writing prompt, neutral writing prompt). This is the exact test that the authors conducted in the original paper.

There are no additional analyses planned at this time.

### Differences from Original Study

The materials used will be identical to the original study, and the replication will be conducted on Amazon Mechanical Turk, the same location as the original study. 

The one difference is time of data collection: data for the original study were collected in 2016 and before, whereas data collection for the replication will be collected in 2019. It is possible that the MTurk population has changed since this time, although there is no reason to expect that any such changes will impact the results of the study.

### Methods Addendum (Post Data Collection)

#### Actual Sample

We finished with a final sample size of 175 participants (mean age: 34.7, 65% female). Of the total, 56 participants were excluded for failing one of the two attention checks, leaving a final sample size of 119 participants (31 in the unethical condition, 43 in the neutral condition, and 45 in the ethical condition).

#### Differences from pre-data collection methods plan

None.

## Results


### Data preparation

```{r}
###Data Preparation
#Step one is to load libraries
library(here)
library(tidyverse)
library(ggthemes)
library(DescTools)
library(heplots)

#Next step is to import the data and make sure it looks ok
setwd(here())
Final_Data <- read.csv("Kouchaki_raw_data.csv")

#Next let's filter out all the columns that we won't be using
Final_Data_fil <- Final_Data %>%
  select(StartDate, Finished, PromptEthical:DemoLang)

#And then let's filter out all the people that weren't in the final round of data collection
Final_Data_fil <- Final_Data_fil %>%
  slice(48:222)

#Let's do a quick demographic check
Final_Data_fil$DemoAge <- as.character(Final_Data_fil$DemoAge)

Final_Data_fil$DemoGen <- as.character(Final_Data_fil$DemoGen)

Final_Data_fil$DemoLang <- as.character(Final_Data_fil$DemoLang)

Final_Data_fil$DemoAge <- as.numeric(Final_Data_fil$DemoAge)

Final_Data_fil$DemoGen <- as.numeric(Final_Data_fil$DemoGen)

Final_Data_fil$DemoLang <- as.numeric(Final_Data_fil$DemoLang)


Final_Data_demo <- Final_Data_fil %>%
  summarise(age_mean = mean(DemoAge),
            gender_prop = mean(DemoGen)
            )

#Next we want to try and make a new column for condition that tells us what prompt the participant got
Final_Data_fil <- Final_Data_fil %>%
  mutate(Condition = case_when(
    grepl("a|e|i|o|u|y", PromptEthical) ~ 1,
    grepl("a|e|i|o|u|y", PromptUnethical) ~ 2, 
    grepl("a|e|i|o|u|y", PromptTypical) ~ 3
  ))

#Now we want to start excluding people. The first step we can actually exclude two of the three groups- those who didn't write anything and those who failed to answer the check where they reported what condition they were in. All we need to do is compare the Condition column to the check column, and if they're not the same exclude them

#This gets rid of rows we don't need
Final_Data_fil <- Final_Data_fil %>% 
  filter(Finished == 1)

#This converts the Condition column to numbers
Final_Data_fil$Condition <- as.numeric(Final_Data_fil$Condition) 

#This converts the Att Check column to numbers
Final_Data_fil$AttCheckSit <-as.numeric(Final_Data_fil$AttCheckSit) 

#This corrects for the fact that when you convert the Att Check column to numbers it screws it up by adding two to everything
Final_Data_fil <- Final_Data_fil %>% 
  mutate(AttCheckSit = AttCheckSit-2) 

#This creates a column that is one if we should keep it and is something else otherwise
Final_Data_fil <- Final_Data_fil %>%
  mutate(Exclude1 = Condition/AttCheckSit) 

#And then this actually does the excluding
Final_Data_fil <- Final_Data_fil %>%
  filter(Exclude1 == 1)

#Now we want to exclude anyone who failed the attention check built into the self-dehumanization scale, which is comparably a lot easier
Final_Data_fil <- Final_Data_fil %>%
  filter(SelfDHCheck == 3)

#Now we can actually start the data analysis portion. First we want to simplify our table a bit to get rid of columns that are now unnecessary
Final_Data_fil <- Final_Data_fil %>%
  select(PromptRelevant, SelfDH1:SelfDH10, Condition)

#Then convert to characters
Final_Data_fil <- Final_Data_fil %>%
    mutate_if(is.factor, as.character)

#And finally convert to numeric- I tried doing this and the previous in one function, but it wouldn't work for some reason
Final_Data_fil <- Final_Data_fil %>%
    mutate_if(is.character, as.numeric)

#Let's make Condition back to a factor, which will be helpful later
Final_Data_fil <- Final_Data_fil %>%
  mutate(Condition = as.factor(Condition))

#Then we can actually calculate the mean scores for each person, which sets us up to perform the confirmatory analysis
Final_Data_fil <- Final_Data_fil %>%
  mutate(SelfDH_Mean = 
           rowMeans(select
                    (., SelfDH1:SelfDH10)))
```

### Confirmatory analysis

```{r}
#Now we can run the actual analysis
aov_results <- aov(SelfDH_Mean ~ Condition, data = Final_Data_fil)

summary(aov_results)

#And get the partial eta squared, which was the original authors' measure of effect size
etasq(aov_results, partial = TRUE)

#Let's add a column that will end up putting nicer labels on the graph
Final_Data_fil <- Final_Data_fil %>%
  mutate(Condition_Label = case_when(
    Condition == 1 ~ "Ethical",
    Condition == 2 ~ "Unethical", 
    Condition == 3 ~ "Neutral")
         )

#Let's also output the data now so that it's accessible in anonymized fashion
write.csv(Final_Data_fil, file = "Kouchaki_replication_data.csv")

#This will allow me to set the order of the bars in the graph to match the original
positions <- c("Unethical", "Ethical", "Neutral")

#And this will set us up to graph the data
Final_Data_sum <- Final_Data_fil %>%
  group_by(Condition_Label) %>%
  summarise(Sample_size = length(Condition_Label),
            Overall_SDH_Mean = mean(SelfDH_Mean),
            Overall_SD = sd(SelfDH_Mean),
            Overall_SE = sd(SelfDH_Mean)/sqrt(length(Condition_Label)))

#I also want to quickly plot the results from the original paper so we can compare side-by-side
Original_Label <- c("Unethical", "Ethical", "Neutral")
Original_Means <- c(5.82, 6.23, 6.16)
Original_SDs <- c(1.11, .65, .73)
Original_ns <- c(49, 54, 53)
Original_Data <- data.frame(Original_Label, Original_Means, Original_SDs, Original_ns)

#And then get the summary to set up the graph
Original_Data_sum = Original_Data %>%
  group_by(Original_Label) %>%
  summarise(Orig_Over_SDH_Mean = mean(Original_Means),
            Orig_Over_SE = Original_SDs/sqrt(Original_ns))
```

```{r dodge-st, fig.show = "hold", out.width = "50%"}
#This let's us plot the original data next to the replication to see how they compare
ggplot(Original_Data_sum, aes(x=Original_Label, y=Orig_Over_SDH_Mean, fill=Original_Label)) +
  geom_bar(position="dodge", stat="identity") +
  scale_fill_brewer(palette="Set1") +
  labs(title="Original Data", y="Mind Attributed to Self") +
  scale_x_discrete(limits = positions) +
  coord_cartesian(ylim=c(4,7)) +
  geom_errorbar(aes(ymin = Orig_Over_SDH_Mean - Orig_Over_SE, ymax = Orig_Over_SDH_Mean + Orig_Over_SE), position = "dodge")

ggplot(Final_Data_sum, aes(x=Condition_Label, y=Overall_SDH_Mean, fill=Condition_Label)) +
  geom_bar(position="dodge", stat="identity") + 
  scale_fill_brewer(palette="Set1") +
  labs(title="Replication Data", y="Mind Attributed to Self") +
  scale_x_discrete(limits = positions) +
  coord_cartesian(ylim=c(4,7)) +
  geom_errorbar(aes(ymin = Overall_SDH_Mean - Overall_SE, ymax = Overall_SDH_Mean + Overall_SE), position = "dodge")
```

### Exploratory analyses

We'll run a couple of exploratory analyses. First, we'll start by looking at individual t-tests comparing the conditions to each other. The authors included this in the original paper, but it was not their primary analysis, so we'll report it here.

```{r}

#First let's split the data out by condition, which will make it easier to run t-tests
ethical_data <- Final_Data_fil %>%
  filter(Condition_Label == "Ethical")

unethical_data <- Final_Data_fil %>%
  filter(Condition_Label == "Unethical")

neutral_data <- Final_Data_fil %>%
  filter(Condition_Label == "Neutral")

#Then we can run the actual tests
t.test(ethical_data$SelfDH_Mean, neutral_data$SelfDH_Mean, alternative = "two.sided")
t.test(ethical_data$SelfDH_Mean, unethical_data$SelfDH_Mean, alternative = "two.sided")
t.test(unethical_data$SelfDH_Mean, neutral_data$SelfDH_Mean, alternative = "two.sided")

```

Next we'll do a quick look at the actual responses, to see if there's anything interesting there. I noticed when scrolling through the responses that there seemed to be a lot of irrelevant responses, so I want to see if excluding those changes the results, as this should exclude people who didn't complete the  manipulation but were able to pass the attention checks.

To do so, I went through the initial data and added a column that had a 1 in it if the textual response could plausibly be seen as an answer to the question and a 0 if it was completely unrelated or unintelligble. I tried to use pretty liberal criteria, and while it would be ideal to have a more careful analysis this should at least give us a sense of whether it makes a difference. Using that data, we can then see if excluding people who didn't write something relevant changes the outcome. 

```{r}
#We'll start by just looking at the proportion of people who had relevant responses after all other exclusions
mean(Final_Data_fil$PromptRelevant)

```

That's interesting- even after excluding people who failed one of the attention checks, about 15% of people had responses that were completely irrelevant. Now we can move on to do a little more data wrangling before actually running the tests to see if excluding this group of people would change our results.


```{r}
#We'll first filter out people who gave irrelevant responses, then summarise the data
Final_Data_response <- Final_Data_fil %>%
  filter(PromptRelevant == 1)

Final_Data_response_sum <- Final_Data_response %>%
  group_by(Condition) %>%
  summarise(Sample_size = length(Condition),
            Overall_SDH_Mean = mean(SelfDH_Mean),
            Overall_SD = sd(SelfDH_Mean),
            Overall_SE = sd(SelfDH_Mean)/sqrt(length(Condition)))

#Here's our actual test- what happens when we run the ANOVA
aov_results_response <- aov(SelfDH_Mean ~ Condition, data = Final_Data_response)

summary(aov_results_response)

#And let's also run the individual t-tests to see if anything changes there
ethical_data_response <- Final_Data_response %>%
  filter(Condition == "1")

unethical_data_response <- Final_Data_response %>%
  filter(Condition == "2")

neutral_data_response <- Final_Data_response %>%
  filter(Condition == "3")

t.test(ethical_data_response$SelfDH_Mean, neutral_data_response$SelfDH_Mean, alternative = "two.sided")
t.test(ethical_data_response$SelfDH_Mean, unethical_data_response$SelfDH_Mean, alternative = "two.sided")
t.test(unethical_data_response$SelfDH_Mean, neutral_data_response$SelfDH_Mean, alternative = "two.sided")
```

I also want to run one final quick analysis to check the Cronbach's Alpha of the scale, to see how internally consistent it is. 

```{r}
#We start by splitting out just the item responses
Final_Data_alpha <- Final_Data_fil %>%
  select(SelfDH1:SelfDH10)

#And then calculate the alpha
CronbachAlpha(Final_Data_alpha)

```

## Discussion

### Summary of Replication Attempt

The confirmatory analysis consisted of an ANOVA comparing the three conditions, F(2, 116) = 8.16, p < .0005. This replicates the original study, and in fact showed a lower p-value (p < .0005 in the replication versus p = 0.033 in the original) and a larger effect size (partial eta squared of 0.12 in the replication versus 0.04 in the original).

### Commentary

Secondary and exploratory analyses provide some interesting context to the replication. In addition to running an ANOVA, the authors also ran t-tests comparing the individual conditions. In the original study, the authors found a significant difference between the unethical and the ethical condition, and a marginal difference between the unethical and the neutral condition, but no difference between the ethical and neutral conditions. In the replication, we also showed a significant difference between the unethical and ethical conditions. But we also showed a signifcant difference between the unethical and neutral condition (where the original study had seen a marginal difference) and a marginal difference between the ethical and neutral conditions, where the authors had seen no difference. The differences were in an expected direction, with participants in the neutral condition showing marginally more self-dehumanization than those in the ethical condition and significantly less self-dehumanization than those in the unethical condition, but it's still interesting to see a result where the authors had observed none. 

Exploratory analyses added some more context to the above finding. An analysis conducted with responses that had been coded as 'irrelevant' removed from the data set (which was not an exclusion criterion in the original study) showed a similar pattern of results. But when these participants were removed, all three of the t-tests described above becamse significant, indicating that among participants who engaged in the manipulation there were significant differences between all three conditions.

Exploratory analyses on the reliability of the scale returned a Cronbach's alpha of 0.91, indicating a highly reliable scale and suggesting that it was not one or two of the items that were driving participants' response, but the scale as a whole. 

There is one other interesting note that should be mentioned. In the original study, the authors excluded 21 out of 177 participants, yielding an exclusion rate of 11.8% and a final sample size of 156. In our replication, we excluded 56 out of 175 participants, yielding an exclusion rate of 32% and a final sample size of 119. Additionally, while the authors didn't indicate a large difference in exclusions between groups (they didn't report exclusions by group but finished with between 49 and 54 participants in each condition), the replication had many more exclusions in the unethical condition (a final sample size of 31 in the unethical condition as compared to 43 in the neutral condition and 45 in the ethical condition). This difference is not particularly surprising, as people may have been uncomfortable writing about an unethical act and thus may have left the space blank at a higher rate, but it is an interesting difference from the original. It also brings into question whether these exclusions meant there was in effect a different subset of participants in the unethical condition than in the other two conditions, and whether this might explain some of our observed results.

On the whole, the replication does provide support for the idea that recalling and writing about an unethical act leads people to dehumanize themselves more. 

The original authors did not raise any objections or challenges regarding the replication attempt.
